{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Supervised Learning\"\n",
    "format:\n",
    "    html: \n",
    "        code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- After digesting the instructions, you can delete this cell, these are assignment instructions and do not need to be included in your final submission.  -->\n",
    "\n",
    "{{< include instructions.qmd >}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#getting data\n",
    "#saved data for easy purpose\n",
    "d1 = pd.read_csv('out.csv')\n",
    "d1= d1.drop(columns=[\"Unnamed: 0\",\"D_cluster\"])\n",
    "#spliting data\n",
    "so_features = d1.drop(columns=['outs','cluster'])\n",
    "so_target = d1['outs']\n",
    "# features except categorical variable\n",
    "pitch_index = ['release_speed', 'release_spin_rate', 'pfx_x', 'pfx_z', 'release_extension']\n",
    "#splitting data in to 80:20 ratio for train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(so_features,so_target,test_size = 0.2)\n",
    "\n",
    "\n",
    "#max_depth tuning process \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "def confusion_plot(y_data, y_pred):\n",
    "    mat = confusion_matrix(y_data, y_pred)\n",
    "    accuracy = round((mat.diagonal().sum() / mat.sum()) * 100, 2)\n",
    "    negative_recall = recall_score(y_data, y_pred, pos_label=0)\n",
    "    negative_precision = precision_score(y_data, y_pred, pos_label=0)\n",
    "    positve_recall= recall_score(y_data, y_pred, pos_label=1)\n",
    "    positve_precision = precision_score(y_data, y_pred, pos_label=1)\n",
    "    \n",
    "    print(f\"ACCURACY: {accuracy}%\")\n",
    "    print(f\"NEGATIVE RECALL(Y=0):{negative_recall}\")\n",
    "    print(f\"NEGATIVE PRECISION(Y=0): {negative_precision}\")\n",
    "    print(f\"POSITIVE RECALL(Y=1): {positve_recall}\")\n",
    "    print(f\"POSITIVE PRECISION (Y=1): {positve_precision}\")\n",
    "    print(np.array(mat))\n",
    "    ConfusionMatrixDisplay(confusion_matrix=mat).plot()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "test_results=[]\n",
    "train_results=[]\n",
    "\n",
    "for num_layer in range(1,20):\n",
    "    model = tree.DecisionTreeClassifier(max_depth=num_layer)\n",
    "    model = model.fit(x_train,y_train)\n",
    "\n",
    "    yp_train=model.predict(x_train)\n",
    "    yp_test=model.predict(x_test)\n",
    "\n",
    "    test_results.append([num_layer,accuracy_score(y_test, yp_test),recall_score(y_test, yp_test,pos_label=0),recall_score(y_test, yp_test,pos_label=1)])\n",
    "    train_results.append([num_layer,accuracy_score(y_train, yp_train),recall_score(y_train, yp_train,pos_label=0),recall_score(y_train, yp_train,pos_label=1)])\n",
    "\n",
    "\n",
    "test_results = pd.DataFrame(test_results, columns=[\"Depth\", \"Accuracy\", \"Negative_recall\", \"Positive_recall\"])\n",
    "train_results = pd.DataFrame(train_results, columns=[\"Depth\", \"Accuracy\", \"Negative_recall\", \"Positive_recall\"])\n",
    "\n",
    "#recycled code from lecture note(plots)\n",
    "plt.plot(train_results[\"Depth\"], train_results[\"Accuracy\"],  marker='o')\n",
    "plt.plot(test_results[\"Depth\"], test_results[\"Accuracy\"],  marker='o')\n",
    "plt.xlabel(\"Number of layers in decision tree(max_depth)\")\n",
    "plt.ylabel(\"Accuracy(Y = 0): Training (blue) and Test(red)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(train_results[\"Depth\"], train_results[\"Negative_recall\"], marker='o')\n",
    "plt.plot(test_results[\"Depth\"], test_results[\"Negative_recall\"], marker='o')\n",
    "plt.xlabel(\"Number of layers in decision tree(max_depth)\")\n",
    "plt.ylabel(\"Recall(Y = 0): Training (blue) and Test(red)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(train_results[\"Depth\"], train_results[\"Positive_recall\"],  marker='o')\n",
    "plt.plot(test_results[\"Depth\"], test_results[\"Positive_recall\"], marker='o')\n",
    "plt.xlabel(\"Number of layers in decision tree(max_depth)\")\n",
    "plt.ylabel(\"Recall(Y = 1): Training (blue) and Test(red)\")\n",
    "plt.show()\n",
    "#fit model with max_depth = 4\n",
    "from sklearn import tree\n",
    "rf_model = tree.DecisionTreeClassifier(max_depth=4)\n",
    "rf_model = rf_model.fit(x_train,y_train)\n",
    "yp_train=rf_model.predict(x_train)\n",
    "yp_test=rf_model.predict(x_test)\n",
    "# getting feature importanc plot\n",
    "rf_feature_importance = rf_model.feature_importances_\n",
    "rf_features  = so_features.columns\n",
    "rf_idx = rf_feature_importance.argsort()\n",
    "\n",
    "# Creating the plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(rf_features[rf_idx], rf_feature_importance[rf_idx], color='orange')\n",
    "plt.xlabel('Importance',size= 10)\n",
    "plt.title('Feature Importance from Random Forest Model',size = 15)\n",
    "plt.show()\n",
    "#confusion matrix and model evaluation\n",
    "print(\"------TRAINING------\")\n",
    "confusion_plot(y_train,yp_train)\n",
    "print(\"------TEST------\")\n",
    "confusion_plot(y_test,yp_test)\n",
    "\n",
    "\n",
    "#model evaluation using rocv curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "rf_prob = rf_model.predict_proba(x_test)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, rf_prob)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, rf_prob)\n",
    "auc_score = roc_auc_score(y_test, rf_prob)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', label=f'ROC curve (area = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for Random Forest ')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#decision tree plot\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(80, 50))\n",
    "plot_tree(\n",
    "    rf_model,\n",
    "    feature_names= x_train.columns,\n",
    "    class_names=[\"in-play\", \"out\"],\n",
    "    filled=True,\n",
    "    rounded=True\n",
    ")\n",
    "plt.title(\"decision tree with max_depth=4\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#starting second objective:  applying this to each clusters(cluster got from kmeans)\n",
    "so_features_clusters = d1.drop(columns=['outs'])\n",
    "cluster_list = []\n",
    "roc_auc_list = {}\n",
    "\n",
    "for cluster_id in so_features_clusters['cluster'].unique():\n",
    "    cluster_data = so_features_clusters[so_features_clusters['cluster'] == cluster_id]\n",
    "    cluster_target = so_target[so_features_clusters['cluster'] == cluster_id]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        cluster_data, cluster_target, test_size=0.2, stratify=cluster_target\n",
    "    )\n",
    "    \n",
    "    cluster_model = RandomForestClassifier(max_depth=6)\n",
    "    cluster_model.fit(x_train, y_train)\n",
    "    y_pred = cluster_model.predict(x_test)\n",
    "\n",
    "\n",
    "    precision = precision_score(y_test, y_pred, average='binary')\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "    cluster_list.append({\n",
    "        'cluster': cluster_id,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': accuracy,\n",
    "        'f1 score': f1\n",
    "    })\n",
    "    y_pred_prob = cluster_model.predict_proba(x_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_auc_list[cluster_id] = roc_auc\n",
    "    \n",
    "\n",
    "    plt.plot(fpr, tpr, label=f'Cluster {cluster_id} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves by Cluster')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "    \n",
    "# Convert the metrics list to a DataFrame\n",
    "metrics_df = pd.DataFrame(cluster_list)\n",
    "metrics_df\n",
    "    \n",
    "\n",
    "\n",
    "#optimizing like before, this time for each clusters\n",
    "test_results=[]\n",
    "train_results=[]\n",
    "cluster_data = so_features_clusters[so_features_clusters['cluster'] == cluster_id]\n",
    "cluster_target = so_target[so_features_clusters['cluster'] == cluster_id]\n",
    "# Train-test split\n",
    "x_train_cluster, x_test_cluster, y_train_cluster, y_test_cluster = train_test_split(\n",
    "        cluster_data, cluster_target, test_size=0.2\n",
    "    )\n",
    "\n",
    "for num_layer in range(1,15):\n",
    "    model = tree.DecisionTreeClassifier(max_depth=num_layer)\n",
    "    model = model.fit(x_train_cluster,y_train_cluster)\n",
    "\n",
    "    yp_train=model.predict(x_train_cluster)\n",
    "    yp_test=model.predict(x_test_cluster)\n",
    "\n",
    "    test_results.append([num_layer,accuracy_score(y_test_cluster, yp_test),recall_score(y_test_cluster, yp_test,pos_label=0),recall_score(y_test, yp_test,pos_label=1)])\n",
    "    train_results.append([num_layer,accuracy_score(y_train_cluster, yp_train),recall_score(y_train_cluster, yp_train,pos_label=0),recall_score(y_train, yp_train,pos_label=1)])\n",
    "\n",
    "\n",
    "test_results = pd.DataFrame(test_results, columns=[\"Depth\", \"Accuracy\", \"Negative_recall\", \"Positive_recall\"])\n",
    "train_results = pd.DataFrame(train_results, columns=[\"Depth\", \"Accuracy\", \"Negative_recall\", \"Positive_recall\"])\n",
    "\n",
    "plt.plot(train_results[\"Depth\"], train_results[\"Accuracy\"],  marker='o')\n",
    "plt.plot(test_results[\"Depth\"], test_results[\"Accuracy\"],  marker='o')\n",
    "plt.xlabel(\"Number of layers in decision tree(max_depth)\")\n",
    "plt.ylabel(\"Accuracy(Y = 0): Training (blue) and Test(red)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(train_results[\"Depth\"], train_results[\"Negative_recall\"], marker='o')\n",
    "plt.plot(test_results[\"Depth\"], test_results[\"Negative_recall\"], marker='o')\n",
    "plt.xlabel(\"Number of layers in decision tree(max_depth)\")\n",
    "plt.ylabel(\"Recall(Y = 0): Training (blue) and Test(red)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(train_results[\"Depth\"], train_results[\"Positive_recall\"],  marker='o')\n",
    "plt.plot(test_results[\"Depth\"], test_results[\"Positive_recall\"], marker='o')\n",
    "plt.xlabel(\"Number of layers in decision tree(max_depth)\")\n",
    "plt.ylabel(\"Recall(Y = 1): Training (blue) and Test(red)\")\n",
    "plt.show()\n",
    "#max_depth will be 4 \n",
    "#intitial storage for evaluation\n",
    "\n",
    "cluster_evaluation = []  \n",
    "\n",
    "for cluster_id in so_features_clusters['cluster'].unique():\n",
    "    cluster_data = so_features_clusters[so_features_clusters['cluster'] == cluster_id]\n",
    "    cluster_target = so_target[so_features_clusters['cluster'] == cluster_id]\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "        cluster_data, cluster_target, test_size=0.2,stratify=cluster_target\n",
    "    )\n",
    "\n",
    "    # Train Random Forest Model\n",
    "    cluster_model = RandomForestClassifier(max_depth =4)\n",
    "    cluster_model.fit(X_train_c, y_train_c)\n",
    "\n",
    "    # Predict and evaluate metrics\n",
    "    y_pred_c = cluster_model.predict(X_test_c)\n",
    "    metrics = {\n",
    "        \"Cluster\": cluster_id,\n",
    "        \"Accuracy\": accuracy_score(y_test_c, y_pred_c),\n",
    "        \"Precision\": precision_score(y_test_c, y_pred_c, average='binary'),\n",
    "        \"Recall\": recall_score(y_test_c, y_pred_c, average='binary'),\n",
    "        \"F1 Score\": f1_score(y_test_c, y_pred_c, average='binary')\n",
    "    }\n",
    "\n",
    "    cluster_evaluation.append(metrics)\n",
    "\n",
    "\n",
    "    y_pred_prob = cluster_model.predict_proba(x_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_auc_list[cluster_id] = roc_auc\n",
    "    \n",
    "\n",
    "    plt.plot(fpr, tpr, label=f'Cluster {cluster_id} (AUC = {roc_auc:.2f})')\n",
    "    \n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves by Cluster(k_means)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "cluster_evaluations = pd.DataFrame(cluster_evaluation)\n",
    "# Probability model using Random Forest\n",
    "\n",
    "# Pitching index that will be used as clustering model\n",
    "pitch_index = ['release_speed', 'release_spin_rate', 'pfx_x', 'pfx_z', 'release_extension']\n",
    "# Splitting data into 80:20 ratio for train and test\n",
    "x_train_prob, x_test_prob, y_train_prob, y_test_prob = train_test_split(so_features_clusters,\n",
    "                                                                        so_target, test_size=0.2, random_state=42)\n",
    "# Fitting random forest model (using max_depth = 4 as before)\n",
    "prob_rf = RandomForestClassifier(max_depth=4, random_state=42)\n",
    "prob_rf.fit(x_train_prob, y_train_prob)\n",
    "y_pred_prob = prob_rf.predict(x_test_prob)\n",
    "\n",
    "# Evaluation criterias: accuracy score,precision score,recall score,f1 score\n",
    "accuracy = accuracy_score(y_test_prob, y_pred_prob)\n",
    "precision = precision_score(y_test_prob, y_pred_prob)\n",
    "recall = recall_score(y_test_prob, y_pred_prob)\n",
    "f1 = f1_score(y_test_prob, y_pred_prob)\n",
    "\n",
    "# Storages to store results\n",
    "cluster_high_success_summaries = {}\n",
    "cluster_high_success_rates = {}\n",
    "cluster_results_accuracy = []\n",
    "\n",
    "# Using for loop to apply all clusters\n",
    "for cluster_id in x_test_prob['cluster'].unique():\n",
    "\n",
    "    # Filtering data for clusters\n",
    "    cluster_data = x_test_prob[x_test_prob['cluster'] == cluster_id]\n",
    "    cluster_target = y_test_prob[x_test_prob['cluster'] == cluster_id]\n",
    "    \n",
    "    # Train-test split for the cluster\n",
    "    X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "        cluster_data, cluster_target, test_size=0.2, stratify=cluster_target, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Use random forest model with same max_depth\n",
    "    cluster_model = RandomForestClassifier(max_depth=4, random_state=42)\n",
    "    cluster_model.fit(X_train_c, y_train_c)\n",
    "    y_pred_c = cluster_model.predict(X_test_c)\n",
    "    \n",
    "    # Evaluation criteria\n",
    "    cluster_accuracy = accuracy_score(y_test_c, y_pred_c)\n",
    "    cluster_precision = precision_score(y_test_c, y_pred_c)\n",
    "    cluster_recall = recall_score(y_test_c, y_pred_c)\n",
    "    cluster_f1 = f1_score(y_test_c, y_pred_c)\n",
    "\n",
    "    # Process to get  successful rate for getting out count for pitchers\n",
    "  \n",
    "    y_pred_proba_c = cluster_model.predict_proba(X_test_c)[:, 1]\n",
    "    cluster_test_results = X_test_c.copy()\n",
    "    cluster_test_results['outs'] = y_test_c\n",
    "    cluster_test_results['out_probability'] = y_pred_proba_c\n",
    "    high_success_conditions = cluster_test_results[cluster_test_results['out_probability'] > 0.75] # this probability can be changed \n",
    "    # but 0.75 is based on the average obp(on base percentage) in 2024 was around 0.312 so set higher criteria. \n",
    "    #https://www.mlb.com/glossary/standard-stats/on-base-percentage\n",
    "\n",
    "    high_success_summary = high_success_conditions[pitch_index].mean()\n",
    "# getting mean of index for 75% outs\n",
    "    # Summarize high success cases\n",
    "    cluster_high_success_summaries[cluster_id] = high_success_conditions[\n",
    "        ['release_spin_rate', 'pfx_x', 'pfx_z', 'release_speed', 'release_extension']\n",
    "    ].mean()\n",
    "\n",
    "    # Store cluster accuracy results\n",
    "    cluster_results_accuracy.append({\n",
    "        'Cluster': cluster_id,\n",
    "        'Accuracy': cluster_accuracy,\n",
    "        'Precision': cluster_precision,\n",
    "        'Recall': cluster_recall,\n",
    "        'F1 Score': cluster_f1\n",
    "    })\n",
    "\n",
    "#make it to dataframe\n",
    "cluster_accuracy_results = pd.DataFrame(cluster_results_accuracy)\n",
    "\n",
    "\n",
    "cluster_results = {\n",
    "    'high_success_summaries': cluster_high_success_summaries\n",
    "}\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
